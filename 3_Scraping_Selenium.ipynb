{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "fb698bdeab99cfbf9e31cab566d99a06e057f2dec3dcc8097ebabb329e860e16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Webscraping with Selenium"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Selenium automates browsers. That's it!\r\n",
    "What you do with that power is entirely up to you.\r\n",
    "\r\n",
    "Primarily Selenium is for automating web applications for testing purposes, but is certainly not limited to just that. You can also use Selenium to automatically retrieve data from webpages and this is exactly what this notebook is about. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Initiating the Webdriver"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Init webdriver - you should initiate the webdriver in a seperate function. Otherwise a new webdriver instance will be initiated whenever you call the function!\r\n",
    "from selenium import webdriver\r\n",
    "\r\n",
    "# Init webdriver normally to see mistakes\r\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\") #make sure that the chromdriver.exe file is in the working directory or that you use the absolut path instead. \r\n",
    "\r\n",
    "# maimizes the browser window -> recommended to consistently find all web objects at the same place. \r\n",
    "driver.maximize_window()\r\n",
    "\r\n",
    "\r\n",
    "# Init webdriver with options \r\n",
    "\"\"\"chrome_options = Options()\r\n",
    "chrome_options.add_argument(\"--headless\")\r\n",
    "    # set screensize to 1920x1080\r\n",
    "chrome_options.add_argument(\"--window-size=1920x1080\")\r\n",
    "driver = webdriver.Chrome(chrome_options=chrome_options, executable_path=chrome_driver)\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "# Init webdriver headless\r\n",
    "\"\"\"\r\n",
    "# Init webdriver headless to increase performance -> only use this method if you know what you are doing ;)\r\n",
    "# get path of webdriver\r\n",
    "\r\n",
    "chrome_driver = webdriver.Chrome(\"D:/Drive/01_Promotion/31_Code/01_Python/GitHub Readme/chromedriver.exe\")\r\n",
    "    # set options of webdriver to headless\r\n",
    "chrome_options = Options()\r\n",
    "chrome_options.add_argument(\"--headless\")\r\n",
    "    # set screensize to 1920x1080\r\n",
    "chrome_options.add_argument(\"--window-size=1920x1080\")\r\n",
    "\r\n",
    "\"\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Navigate the Webdriver"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# navigate webdriver\r\n",
    "    # the following call navigate your browser window to the quotes to scrape website \r\n",
    "try:\r\n",
    "    driver.get(\"https://quotes.toscrape.com/\")\r\n",
    "except:\r\n",
    "    print(\"webdriver failure\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "author =  driver.find_element_by_xpath(\"/html/body/div/div[2]/div[1]/div[1]/span[2]/small\").text\r\n",
    "author"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Albert Einstein'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Finding elements with Selenium"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Selenium offers a variety of options to find and interact with element on a website. Below we only showcase few examples but you can check out the Selenium documentation (https://selenium-python.readthedocs.io/locating-elements.html) to discover different ways to locate elements. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# finding an author name by XPATH\r\n",
    "    # hint: by right-clicking on the item on the website you can open Google's \"inspect\" mode. If you right-click on the element in the HTML code of the inspect window, you can copy the XPATH.\r\n",
    "XPATH = \"/html/body/div/div[2]/div[1]/div[1]/span[2]/small\"\r\n",
    "author = driver.find_element_by_xpath(XPATH).text\r\n",
    "\r\n",
    "print(author)\r\n",
    "\r\n",
    "\r\n",
    "# finding an author name by ID\r\n",
    "ID = \"insert ID\"\r\n",
    "author = driver.find_element_by_id(ID).text\r\n",
    "print(author)\r\n",
    "\r\n",
    "# finding an author name by tag name\r\n",
    "tag_name = \"insert tag name\"\r\n",
    "author = driver.find_element_by_tag_name(tag_name).text\r\n",
    "print(author)\r\n",
    "\r\n",
    "# finding an author name by class name\r\n",
    "class_name = \"insert class name\"\r\n",
    "author = driver.find_element_by_class_name(class_name).text\r\n",
    "print(author)\r\n",
    "\r\n",
    "# finding an author name by css_selector\r\n",
    "css_selector = \"insert css selector\"\r\n",
    "author = driver.find_element_by_css_selector(css_selector).text\r\n",
    "print(author)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# find multiple elements \r\n",
    "    # you can also find a list of multiple element \r\n",
    "    # once you got the list you need to iterate through the list if you want to access the individual items\r\n",
    "    # you can use the following methods to retrieve the list\r\n",
    "author_list = driver.find_elements_by_name()\r\n",
    "author_list = driver.find_elements_by_xpath()\r\n",
    "author_list = driver.find_elements_by_link_text()\r\n",
    "author_list = driver.find_elements_by_partial_link_text()\r\n",
    "author_list = driver.find_elements_by_tag_name()\r\n",
    "author_list = driver.find_elements_by_class_name()\r\n",
    "author_list = driver.find_elements_by_css_selector()\r\n",
    "\r\n",
    "# iterating through the lists\r\n",
    "for author in author_list:\r\n",
    "    print(author.text)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 Interacting with elements "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Selenium also allows you to interact with all elements on a webpage that a normal user can usually interact with. E.g., it can click button to go through different subpages. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# interacting with a buttion\r\n",
    "    # frist you need to import the ActionChains module of Selenium\r\n",
    "from selenium.webdriver import ActionChains\r\n",
    "\r\n",
    "    # then you need to find the button element. You can chose every \"find\" method you want\r\n",
    "button = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[1]/nav/ul/li[2]/a\")\r\n",
    "\r\n",
    "    # finally you need to pass the button into the click method of the action chain object that takes you webdriver as an argument and call the perform method\r\n",
    "ActionChains(driver).click(button).perform()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scraping Example 2 - Scraping a real live page "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}